I"h<ol>
  <li><a href="#learning-objectives">Learning objectives</a></li>
  <li><a href="#overview">Overview</a></li>
  <li><a href="#activity">Activity</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ol>

<h4 id="learning-objectives">Learning Objectives</h4>

<ul>
  <li>Gain exposure to the concept of data locality.</li>
  <li>Be able to quantify the impact of data locality on workflow execution.</li>
</ul>

<h4 id="workflow-and-platform-scenario">Workflow and Platform Scenario</h4>

<p>In this activity, we study the execution of the workflow depicted in Figure 1 below.</p>

<object class="figure" type="image/svg+xml" data="/wrench-pedagogic-modules/public/img/workflow_execution_data_locality/workflow.svg">Workflow</object>

<p>We wish to execute this workflow on the cyberinfrastructure depicted in
Figure 2 below (which is the same as that used in the previous module). To
summarize, a Compute Service (CS) at host <code class="highlighter-rouge">hpc.edu</code> has a single core that
can execute workflow tasks (but only one at a time). Workflow files are
stored on the Storage Service (SS) at host <code class="highlighter-rouge">storage_db.edu</code> that handles
read and write requests.</p>

<object class="figure" type="image/svg+xml" data="/wrench-pedagogic-modules/public/img/workflow_execution_data_locality/cyber_infrastructure.svg">Cyberinfrastructure</object>

<p>Like in the previous module, the WMS executes tasks as soon as they are
ready, so that each task runs on the CS and reads/writes all files on the
SS. Whenever multiple tasks are ready at the same time, 
as will be the case after <em>task0</em> has completed, 
the WMS arbitrarily runs them in lexicographical order (i.e., 
<em>task1</em>, then <em>task2</em>, and then <em>task3</em>).</p>

<p>So that you can gain hands-on experience, use 
the simulation Web application
(see <a href="/wrench-pedagogic-modules/pedagogic_modules/simulation_instructions/index/" target="_blank">instructions</a>),
selecting <code class="highlighter-rouge">Workflow Execution: Data Locality</code> from its menu.</p>

<p>In the simulation app, for now, just click on the “Run
Simulation” button, without changing the content of the text box or clicking
any radio button. The Web app displays textual and
visual simulation output.</p>

<p><strong>Based on this output, answer the following questions:</strong></p>

<p><strong>[F.q1.1]</strong> Is the workflow execution I/O-intensive or compute-intensive?</p>

<p><strong>[F.q1.2]</strong> If the link bandwidth between <code class="highlighter-rouge">storage_db.edu</code> and <code class="highlighter-rouge">hpc.edu</code> were
         doubled, what fraction of <em>task4</em>’s execution time would be spent doing I/O? (answer this without re-running the simulation)</p>

<p><strong>[F.q1.3]</strong> Double the platform link bandwidth (set it to 20 MB/sec) using the simulation app and re-run the simulation. Is your expectation in q2 confirmed?</p>

<p><strong>[F.q1.4]</strong> Using analysis (i.e., a simple equation), determine the link bandwidth that would be necessary for the workflow to run 2x faster than with the original 10 MB/sec bandwidth?</p>

<p><strong>[F.q1.5]</strong> Using the simulator, report on the accuracy of the result from your analysis in the previous question.</p>

<h4 id="data-locality">Data Locality</h4>

<p>In the workflow execution above, the CS reads and writes files from and to
the SS on <code class="highlighter-rouge">storage_db.edu</code>, which causes a lot of I/O overhead. This
overhead can be vastly reduced if the storage service were located on the
same host as the CS (which you can think of as a disk on which data can be
cached at the SS). The idea would thus be to data <em>closer</em> to where the
computation is taking place, or improving <strong>data locality</strong>.</p>

<p>Figure 3 below shows on the left-hand side a depiction of the new
cyberinfrastructure, on which a second SS is started at host <code class="highlighter-rouge">hpc.edu</code>.</p>

<object class="figure" type="image/svg+xml" data="/wrench-pedagogic-modules/public/img/workflow_execution_data_locality/scenario_2.svg">Scenario 2</object>

<p>We have enhanced the WMS implementation so that it  can take advantage of
the new SS for storing all the “intermediate” workflow files, i.e., those
files shown in red on the right-hand side of Figure 3 above. The only files
that need to be transferred from/to the SS on <code class="highlighter-rouge">storage_db.edu</code> will thus be
initial <em>task0::0.in</em> file and the final output file, <em>task4::0.out</em>.</p>

<p>The above enhancement can be activated by selecting the radio button that
says <em>Storage Service on storage_db.edu and hpc.edu</em>. Leaving the bandwidth
at 10 MB/sec, select the radio button and click the “Run Simulation”
button.</p>

<p><strong>Answer the following questions based on the simulation output</strong>:</p>

<p><strong>[F.q1.6]</strong> What fraction of the workflow execution is spent doing I/O?</p>

<p><strong>[F.q1.7]</strong> Compared to the workflow execution time when there is a single SS, how much faster is the workflow execution now?</p>

<hr />
:ET